{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c3773b",
   "metadata": {},
   "source": [
    "# Here are the library you need to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "from torch import nn\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import scipy.io\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "from timm.models.layers import DropPath\n",
    "from einops import rearrange\n",
    "from scipy import ndimage\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "from natsort import natsorted\n",
    "from skimage.transform import rotate, AffineTransform\n",
    "from timm.models.layers import DropPath, to_3tuple, trunc_normal_\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,    \n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    ToTensord,\n",
    "    RandAffined,\n",
    "    RandCropByLabelClassesd,\n",
    "    SpatialPadd,\n",
    "    RandAdjustContrastd,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityd,\n",
    "    NormalizeIntensityd,\n",
    "    RandScaleIntensityd,\n",
    "    RandGaussianNoised,\n",
    "    RandGaussianSmoothd,\n",
    "    ScaleIntensityRangePercentilesd,\n",
    "    Resized,\n",
    "    Transposed,\n",
    "    ResizeWithPadOrCropd\n",
    ")\n",
    "from monai.transforms import (CastToTyped,\n",
    "                              Compose, CropForegroundd, EnsureChannelFirstd, LoadImaged,\n",
    "                              NormalizeIntensity, RandCropByPosNegLabeld,\n",
    "                              RandFlipd, RandGaussianNoised,\n",
    "                              RandGaussianSmoothd, RandScaleIntensityd,\n",
    "                              RandZoomd, SpatialCrop, SpatialPadd, EnsureTyped)\n",
    "\n",
    "#The diffusion module adpated from https://github.com/openai/guided-diffusion\n",
    "from diffusion.Create_diffusion import *\n",
    "from diffusion.resampler import *\n",
    "from diffusion.normal_diffusion import GaussianDiffusionSampler, GaussianDiffusionTrainer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"CUDA可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA版本: {torch.version.cuda}\")\n",
    "    print(f\"GPU设备: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e4aa7",
   "metadata": {},
   "source": [
    "# Build the data loader using the monai library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a750f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the dataloader hyper-parameters, including the batch size,\n",
    "# image size, image spacing, and color channel (usually 1 for medical images)\n",
    "BATCH_SIZE_TRAIN = 4*1\n",
    "image_size = 256\n",
    "img_size = (image_size,image_size)\n",
    "spacing = (1,1)\n",
    "channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b3a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,imgs_path):\n",
    "        self.imgs_path = imgs_path\n",
    "        # 只搜索常见图像格式\n",
    "        extensions = ['*.png', '*.jpg', '*.jpeg', '*.tiff', '*.bmp']\n",
    "        file_list = []\n",
    "        \n",
    "        for ext in extensions:\n",
    "            file_list.extend(glob.glob(os.path.join(self.imgs_path, ext)))\n",
    "        \n",
    "        file_list = natsorted(file_list, key=lambda y: y.lower())\n",
    "        self.data = []\n",
    "        \n",
    "        for img_path in file_list:\n",
    "            if os.path.exists(img_path):\n",
    "                class_name = os.path.basename(img_path)\n",
    "                self.data.append([img_path, class_name])\n",
    "        \n",
    "        print(f\"找到 {len(self.data)} 个图像文件\")\n",
    "        \n",
    "        # 简化的变换链，移除可能导致问题的变换\n",
    "        self.train_transforms = Compose(\n",
    "                [\n",
    "                    LoadImaged(keys=[\"image\"]),  # 使用默认读取器\n",
    "                    EnsureChannelFirstd(keys=[\"image\"]),\n",
    "                    ScaleIntensityd(keys=[\"image\"], minv=-1, maxv=1.0),\n",
    "                    ResizeWithPadOrCropd(\n",
    "                        keys=[\"image\"],\n",
    "                        spatial_size=(256,256),\n",
    "                        constant_values = -1,\n",
    "                    ),\n",
    "                    ToTensord(keys=[\"image\"]),\n",
    "                ]\n",
    "            )\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx,):\n",
    "        img_path, class_name = self.data[idx]\n",
    "        cao = {\"image\": img_path}\n",
    "        affined_data_dict = self.train_transforms(cao)                    \n",
    "        img_tensor = affined_data_dict['image'].to(torch.float)\n",
    "        \n",
    "        return img_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3f0d8",
   "metadata": {},
   "source": [
    "# Build the TDM process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9698a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These three parameters: training steps number, learning variance or not (using improved DDPM or original DDPM), and inference \n",
    "# timesteps number (only effective when using improved DDPM)\n",
    "diffusion_steps=1000\n",
    "learn_sigma=True\n",
    "timestep_respacing=[50]\n",
    "\n",
    "# Don't toch these parameters, they are irrelant to the image synthesis\n",
    "sigma_small=False\n",
    "class_cond=False\n",
    "noise_schedule='linear'\n",
    "use_kl=False\n",
    "predict_xstart=False\n",
    "rescale_timesteps=True\n",
    "rescale_learned_sigmas=True\n",
    "use_checkpoint=False\n",
    "\n",
    "\n",
    "diffusion = create_gaussian_diffusion(\n",
    "    steps=diffusion_steps,\n",
    "    learn_sigma=learn_sigma,\n",
    "    sigma_small=sigma_small,\n",
    "    noise_schedule=noise_schedule,\n",
    "    use_kl=use_kl,\n",
    "    predict_xstart=predict_xstart,\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    rescale_learned_sigmas=rescale_learned_sigmas,\n",
    "    timestep_respacing=timestep_respacing,\n",
    ")\n",
    "schedule_sampler = UniformSampler(diffusion)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e1924",
   "metadata": {},
   "source": [
    "# Build the TDM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6250173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here enter your network parameters:num_channels means the initial channels in each block,\n",
    "# channel_mult means the multipliers of the channels (in this case, 128,128,256,256,512,512 for the first to the sixth block),\n",
    "# attention_resulution means we use the transformer blocks in the third to the sixth block\n",
    "# number of heads, window size in each transformer block\n",
    "# \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_channels=128\n",
    "channel_mult = (1, 1, 2, 2, 4, 4)\n",
    "attention_resolutions=\"64,32,16,8\"\n",
    "num_heads=[4,4,4,8,16,16]\n",
    "window_size = [[4,4],[4,4],[4,4],[8,8],[8,8],[4,4]]\n",
    "num_res_blocks = [2,2,1,1,1,1]\n",
    "sample_kernel=([2,2],[2,2],[2,2],[2,2],[2,2]),\n",
    "\n",
    "attention_ds = []\n",
    "for res in attention_resolutions.split(\",\"):\n",
    "    attention_ds.append(int(res))\n",
    "class_cond = False\n",
    "use_scale_shift_norm=True\n",
    "resblock_updown = False\n",
    "\n",
    "from network.Diffusion_model_transformer import *\n",
    "model = SwinVITModel(\n",
    "        image_size=(image_size,image_size),\n",
    "        in_channels=1,\n",
    "        model_channels=num_channels,\n",
    "        out_channels=2,\n",
    "        sample_kernel=sample_kernel,\n",
    "        num_res_blocks=num_res_blocks,\n",
    "        attention_resolutions=tuple(attention_ds),\n",
    "        dropout=0,\n",
    "        channel_mult=channel_mult,\n",
    "        num_classes=(NUM_CLASSES if class_cond else None),\n",
    "        use_checkpoint=False,\n",
    "        use_fp16=False,\n",
    "        num_heads=num_heads,\n",
    "        window_size = window_size,\n",
    "        num_head_channels=64,\n",
    "        num_heads_upsample=-1,\n",
    "        use_scale_shift_norm=use_scale_shift_norm,\n",
    "        resblock_updown=resblock_updown,\n",
    "        use_new_attention_order=False,\n",
    "    ).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0393fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #In case you want to use CNN\n",
    "# from network.Diffusion_model_Unet import *\n",
    "# model = UNetModel(\n",
    "#         image_size=image_size,\n",
    "#         in_channels=1,\n",
    "#         model_channels=num_channels,\n",
    "#         out_channels=2,\n",
    "#         num_res_blocks=num_res_blocks[0],\n",
    "#         attention_resolutions=tuple(attention_ds),\n",
    "#         dropout=0.,\n",
    "#         sample_kernel=sample_kernel,\n",
    "#         channel_mult=channel_mult,\n",
    "#         num_classes=(NUM_CLASSES if class_cond else None),\n",
    "#         use_checkpoint=False,\n",
    "#         use_fp16=False,\n",
    "#         num_heads=4,\n",
    "#         num_head_channels=64,\n",
    "#         num_heads_upsample=-1,\n",
    "#         use_scale_shift_norm=use_scale_shift_norm,\n",
    "#         resblock_updown=False,\n",
    "#         use_new_attention_order=False,\n",
    "#     ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d12c7c5",
   "metadata": {},
   "source": [
    "# Call the optimizer and ready for start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e983d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print('parameter number is '+str(pytorch_total_params))\n",
    "torch.backends.cudnn.benchmark = True\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5,weight_decay = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb44eb1",
   "metadata": {},
   "source": [
    "# Build the training function. Run the training function once = one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we explain the training process\n",
    "def train(model, optimizer,data_loader1, loss_history):\n",
    "    \n",
    "    #1: set the model to training mode\n",
    "    model.train()\n",
    "    total_samples = len(data_loader1.dataset)\n",
    "    loss_sum = []\n",
    "    total_time = 0\n",
    "    \n",
    "    #2: Loop the whole dataset, x1 (traindata) is the image batch\n",
    "    for i, x1 in enumerate(data_loader1):\n",
    "\n",
    "        traindata = x1.to(device)\n",
    "        \n",
    "        #3: extract random timestep for training\n",
    "        t, weights = schedule_sampler.sample(traindata.shape[0], device)\n",
    "\n",
    "        aa = time.time()\n",
    "        \n",
    "        #4: Optimize the TDM network\n",
    "        optimizer.zero_grad()\n",
    "        all_loss = diffusion.training_losses(model,traindata,t=t)\n",
    "        loss = (all_loss[\"loss\"] * weights).mean()\n",
    "        loss.backward()\n",
    "        loss_sum.append(loss.detach().cpu().numpy())\n",
    "        optimizer.step()\n",
    "        \n",
    "        #5:print out the intermediate loss for every 100 batches\n",
    "        total_time += time.time()-aa\n",
    "        if i % 100 == 0:\n",
    "            print('optimization time: '+ str(time.time()-aa))\n",
    "            print('[' +  '{:5}'.format(i * BATCH_SIZE_TRAIN) + '/' + '{:5}'.format(total_samples) +\n",
    "                  ' (' + '{:3.0f}'.format(100 * i / len(data_loader1)) + '%)]  Loss: ' +\n",
    "                  '{:6.7f}'.format(np.nanmean(loss_sum)))\n",
    "\n",
    "    #6: print out the average loss for this epoch\n",
    "    average_loss = np.nanmean(loss_sum) \n",
    "    loss_history.append(average_loss)\n",
    "    print(\"Total time per sample is: \"+str(total_time))\n",
    "    print('Averaged loss is: '+ str(average_loss))\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b32db",
   "metadata": {},
   "source": [
    "# Build the testing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105082c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the evaluate function will generate 4 samples and will be save to a folder in MAT format\n",
    "num_sample = 4\n",
    "def evaluate(model,epoch,path):\n",
    "    model.eval()\n",
    "    aa = time.time()\n",
    "    prediction = []\n",
    "    true = []\n",
    "    img = []\n",
    "    loss_all = []\n",
    "    with torch.no_grad():\n",
    "        x_clean = diffusion.p_sample_loop(model,(num_sample, 1, image_size, image_size),clip_denoised=True)\n",
    "        img.append(x_clean.cpu().numpy())\n",
    "    print('Generate for the epoch #'+str(epoch)+' result:')\n",
    "    plt.rcParams['figure.figsize'] = [20, 20]\n",
    "    plt.figure()\n",
    "    f, axarr = plt.subplots(1,num_sample)\n",
    "    for ind in range(num_sample):\n",
    "        axarr[ind].imshow(x_clean[ind,0,:,:].cpu().numpy(), cmap='gray')\n",
    "    plt.show()\n",
    "    data = {\"img\":img}\n",
    "    print(str(time.time()-aa))\n",
    "    scipy.io.savemat(path+ 'test_example_epoch'+str(epoch)+'.mat',data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc474b1",
   "metadata": {},
   "source": [
    "# Start the training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311f54bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "# Enter your data folder\n",
    "training_set1 = CustomDataset('D:\\\\0-nebula\\\\dataset\\\\ixi_paried\\\\t2_resized')\n",
    "# Enter your data reader parameters\n",
    "params = {'batch_size': BATCH_SIZE_TRAIN,\n",
    "          'shuffle': True,\n",
    "          'pin_memory': True,\n",
    "          'drop_last': False}\n",
    "train_loader1 = torch.utils.data.DataLoader(training_set1, **params)\n",
    "\n",
    "# Enter your total number of epoch\n",
    "N_EPOCHS = 200\n",
    "\n",
    "# Enter the address you save the checkpoint and the evaluation examples\n",
    "path =\"cehckpoints/\"\n",
    "PATH = path+'ViTRes1.pt' # Use your own path\n",
    "best_loss = 1\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path) \n",
    "\n",
    "train_loss_history = []\n",
    "\n",
    "# 使用tqdm.notebook为epoch显示进度条\n",
    "for epoch in tqdm(range(N_EPOCHS), desc='训练进度', ncols=800):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 训练一个epoch\n",
    "    average_loss = train(model, optimizer, train_loader1, train_loss_history)\n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    # 每5个epoch进行评估\n",
    "    if epoch % 5 == 0:\n",
    "        evaluate(model, epoch, path)\n",
    "        print('Save the latest best model')\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "\n",
    "print('Training completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2dd4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
